{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbTbXLigwTKL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import distance_mat\n",
        "import ant_colony_opt\n",
        "import map_generator\n",
        "\n",
        "OW_KEY = \"9139450c44e00d180bec88e243c971e4\"\n",
        "\n",
        "OW_ENDPOINT = \"http://api.openweathermap.org/geo/1.0/direct\"\n",
        "\n",
        "\n",
        "with open('cities.txt',mode='r') as file:\n",
        "    cities = file.readlines()\n",
        "\n",
        "for i in range(len(cities)):\n",
        "    cities[i] = cities[i].replace(\"\\n\",\"\")\n",
        "\n",
        "# co_ordinates = []\n",
        "# for city in cities:\n",
        "#     PARAMS = {\n",
        "#         \"q\": f\"{city},IN\",\n",
        "#         \"limit\": 1,\n",
        "#         \"appid\": OW_KEY,\n",
        "#     }\n",
        "#     print(city)\n",
        "#     response = requests.get(url=OW_ENDPOINT, params=PARAMS).json()[0]\n",
        "#     co_ordinates.append((response['lat'], response['lon']))\n",
        "#\n",
        "# print(co_ordinates)\n",
        "# print(len(co_ordinates))\n",
        "co_ordinates = [(25.3356491, 83.0076292), (16.4329976, 80.9937151), (14.6783221, 77.6065039), (17.360589, 78.4740613), (25.4381302, 81.8338005), (9.2844657, 79.3125553), (19.7668121, 74.4754386), (25.1737019, 75.8574194), (26.9154576, 75.8189817), (28.6517178, 77.2219388), (23.0216238, 72.5797068), (22.5414185, 88.35769124388872), (23.2584857, 77.401989), (34.0747444, 74.8204443), (25.6093239, 85.1235252), (23.3700501, 85.3250387), (23.1608938, 79.9497702), (19.0785451, 72.878176), (31.1041526, 77.1709729), (23.7952809, 86.4309638), (25.6618755, 94.1019156), (24.7991162, 93.9364419), (25.5760446, 91.8825282), (14.4493717, 79.9873763), (13.0836939, 80.270186), (28.0159286, 73.3171367), (26.4609135, 80.3217588), (12.9767936, 77.590082), (20.4686, 85.8792), (9.931308, 76.2674136)]\n",
        "\n",
        "dist_mat = distance_mat.Distance_matrix(co_ordinates)\n",
        "\n",
        "distance_matrix = dist_mat.create_distance_mat()\n",
        "\n",
        "# Define parameters\n",
        "num_cities = len(distance_matrix)\n",
        "num_episodes = 2000\n",
        "learning_rate = 0.1\n",
        "discount_factor = 0.9\n",
        "epsilon = 0.1\n",
        "\n",
        "# Initialize Q-table\n",
        "Q = np.zeros((num_cities, num_cities))\n",
        "\n",
        "\n",
        "# Define epsilon-greedy policy\n",
        "def epsilon_greedy_policy(state, epsilon):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return np.random.choice(range(num_cities))\n",
        "    else:\n",
        "        return np.argmax(Q[state, :])\n",
        "\n",
        "\n",
        "# Run Q-learning algorithm\n",
        "for episode in range(num_episodes):\n",
        "    # Start from a random city\n",
        "    current_city = np.random.choice(range(num_cities))\n",
        "    total_reward = 0\n",
        "    visited_cities = [current_city]\n",
        "\n",
        "    # Perform a full tour\n",
        "    for _ in range(num_cities - 1):\n",
        "        next_city = epsilon_greedy_policy(current_city, epsilon)\n",
        "        while next_city in visited_cities:\n",
        "            next_city = epsilon_greedy_policy(current_city, epsilon)\n",
        "\n",
        "        reward = -distance_matrix[current_city, next_city]\n",
        "\n",
        "        # Update Q-table using Q-learning update rule\n",
        "        Q[current_city, next_city] += learning_rate * (\n",
        "                    reward + discount_factor * np.max(Q[next_city, :]) - Q[current_city, next_city])\n",
        "\n",
        "        total_reward += reward\n",
        "        visited_cities.append(next_city)\n",
        "        current_city = next_city\n",
        "\n",
        "    # Return to the starting city\n",
        "    reward = -distance_matrix[current_city, visited_cities[0]]\n",
        "    total_reward += reward\n",
        "    Q[current_city, visited_cities[0]] += learning_rate * (\n",
        "                reward + discount_factor * np.max(Q[visited_cities[0], :]) - Q[current_city, visited_cities[0]])\n",
        "\n",
        "    # Print total reward for each episode\n",
        "    print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
        "\n",
        "# Initialize variables to track the path and its length\n",
        "best_ans=10000000\n",
        "visited_tour=[0]\n",
        "for x in range(num_cities-1):\n",
        "    current_city = x\n",
        "    total_length = 0\n",
        "    visited_cities = [current_city]\n",
        "\n",
        "    # Perform a full tour\n",
        "    for _ in range(num_cities - 1):\n",
        "        next_city = np.argmax(Q[current_city, :])\n",
        "        while next_city in visited_cities:\n",
        "            Q[current_city, next_city] = -100000\n",
        "            next_city = np.argmax(Q[current_city, :])\n",
        "\n",
        "        visited_cities.append(next_city)\n",
        "        total_length += distance_matrix[current_city, next_city]\n",
        "        current_city = next_city\n",
        "\n",
        "        # Break out of the loop if all cities have been visited and returned to the starting city\n",
        "        if len(visited_cities) == num_cities and current_city == 0:\n",
        "            break\n",
        "    total_length+=distance_matrix[current_city,x]\n",
        "    visited_cities.append(x)\n",
        "    if(best_ans>total_length):\n",
        "        visited_tour=visited_cities\n",
        "        best_ans=min(best_ans,total_length)\n",
        "# Print the optimal tour and its length\n",
        "print(\"Optimal Tour:\", visited_tour)\n",
        "print(\"Total Length of Journey:\", best_ans)\n",
        "map = map_generator.Map_generator(cities,co_ordinates,visited_tour)"
      ]
    }
  ]
}